# Copy this file to .env and fill in your actual API keys

# Embedding provider: "mistral" or "openai"
EMBEDDING_PROVIDER=mistral

# Mistral AI API key for embeddings (required if EMBEDDING_PROVIDER=mistral)
MISTRAL_API_KEY=your_mistral_api_key_here

# OpenAI API key for question answering and embeddings (if using OpenAI embeddings)
OPENAI_API_KEY=your_openai_api_key_here

# OpenAI API base URL (usually this default value)
OPENAI_API_BASE=https://api.openai.com/v1

# Model configuration (optional - will use defaults if not set)
MISTRAL_MODEL=mistral-embed
OPENAI_MODEL=gpt-4-turbo
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Database configuration (these are the defaults used in docker-compose.yml)
DB_HOST=localhost
DB_PORT=5432
DB_NAME=rag_db
DB_USER=rag_user
DB_PASSWORD=rag_password

# Document chunking configuration
# Maximum tokens per chunk for embedding API (Mistral limit is 8192)
MAX_CHUNK_TOKENS=6000
# Token threshold to trigger chunking (documents larger than this will be split)
CHUNK_THRESHOLD_TOKENS=7000
